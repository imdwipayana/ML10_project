{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3e07c-04fd-4ee5-ba52-2a4da34637d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfe06d-7c3f-4722-9421-bc963c7aa725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c1ccd2-6bef-4752-903f-10d3e63037e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf08c8b-8f36-46eb-bae7-2ba711ca9993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daebb51-5a59-4a89-8425-ef1997626724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Running Grid Search for XGBoost hyperparameters...\n",
      "Fitting 5 folds for each of 48020 candidates, totalling 240100 fits\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# STEP 1: IMPORTS\n",
    "# =============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, label_binarize\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "obesity = pd.read_csv(\"obesity.csv\")\n",
    "# change the target name from \"NObeyesdad\" to \"target\"\n",
    "obesity.rename(columns={\"NObeyesdad\": \"Target\"}, inplace=True)\n",
    "\n",
    "target_map = {\n",
    "    \"Insufficient_Weight\": 0,\n",
    "    \"Normal_Weight\": 1,\n",
    "    \"Overweight_Level_I\": 2,\n",
    "    \"Overweight_Level_II\": 3,\n",
    "    \"Obesity_Type_I\": 4,\n",
    "    \"Obesity_Type_II\": 5,\n",
    "    \"Obesity_Type_III\": 6\n",
    "}\n",
    "\n",
    "obesity[\"Target\"] = obesity[\"Target\"].map(target_map)\n",
    "\n",
    "# =============================================\n",
    "# STEP 2: DATA SPLIT (your setup)\n",
    "# =============================================\n",
    "X = obesity.drop(columns=[\"Target\"])\n",
    "y = obesity[\"Target\"]\n",
    "\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# =============================================\n",
    "# STEP 3: PREPROCESSING\n",
    "# =============================================\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_features),\n",
    "        ('cat', categorical_transformer, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =============================================\n",
    "# STEP 4: MODEL PIPELINE\n",
    "# =============================================\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb_clf)\n",
    "])\n",
    "\n",
    "# =============================================\n",
    "# STEP 5: HYPERPARAMETER TUNING\n",
    "# =============================================\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 75, 100, 125, 150, 175, 200],\n",
    "    'classifier__max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "    'classifier__learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2],\n",
    "    'classifier__subsample': [0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1],\n",
    "    'classifier__colsample_bytree': [0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"üîç Running Grid Search for XGBoost hyperparameters...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ Best Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# =============================================\n",
    "# STEP 6: PREDICTIONS USING BEST MODEL\n",
    "# =============================================\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# =============================================\n",
    "# STEP 7: METRICS\n",
    "# =============================================\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "rec = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"\\nüìä Performance Metrics:\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision (macro): {prec:.4f}\")\n",
    "print(f\"Recall (macro):    {rec:.4f}\")\n",
    "print(f\"F1-score (macro):  {f1:.4f}\")\n",
    "\n",
    "# =============================================\n",
    "# STEP 8: CONFUSION MATRIX (Publication-Grade)\n",
    "# =============================================\n",
    "plt.figure(figsize=(6, 5))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Confusion Matrix\", fontsize=14, weight='bold')\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# STEP 9: ROC AUC (One-vs-Rest, Publication-Grade)\n",
    "# =============================================\n",
    "n_classes = len(np.unique(y))\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n",
    "    auc_score = roc_auc_score(y_test_bin[:, i], y_proba[:, i])\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {auc_score:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Chance')\n",
    "plt.title('ROC Curves (One-vs-Rest)', fontsize=16, weight='bold')\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "plt.legend(loc='lower right', fontsize=10, frameon=True)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = f\"ROC_AUC_XGBoost.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Model evaluation completed with best-tuned XGBoost classifier.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5e2b3-aa31-406b-9ce7-e577f5f86bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check train vs testing accuracy\n",
    "# Example using your pipeline (best_model)\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ee2c1-f296-4a25-a563-84e16855fe3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2111c2-05fb-429c-af35-f24ee280d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# STEP 1: IMPORTS\n",
    "# =============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# =============================================\n",
    "# STEP 2: DATA SPLIT (your setup)\n",
    "# =============================================\n",
    "# X = obesity.drop(columns=[\"Target\"])\n",
    "# y = obesity[\"Target\"]\n",
    "\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# =============================================\n",
    "# STEP 3: PREPROCESSING\n",
    "# =============================================\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_features),\n",
    "        ('cat', categorical_transformer, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =============================================\n",
    "# STEP 4: MODEL PIPELINE\n",
    "# =============================================\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb_clf)\n",
    "])\n",
    "\n",
    "# =============================================\n",
    "# STEP 5: TRAIN MODEL\n",
    "# =============================================\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# =============================================\n",
    "# STEP 6: PREDICTIONS\n",
    "# =============================================\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]  # for ROC\n",
    "\n",
    "# =============================================\n",
    "# STEP 7: METRICS (Multiclass version)\n",
    "# =============================================\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "rec = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision (macro): {prec:.4f}\")\n",
    "print(f\"Recall (macro):    {rec:.4f}\")\n",
    "print(f\"F1-score (macro):  {f1:.4f}\")\n",
    "\n",
    "# =============================================\n",
    "# STEP 8: CONFUSION MATRIX\n",
    "# =============================================\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Confusion Matrix\", fontsize=14, weight='bold')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================\n",
    "# STEP 9: ROC AUC (One-vs-Rest, Publication-grade)\n",
    "# =============================================\n",
    "# Only if you want ROC for multiclass\n",
    "n_classes = len(np.unique(y))\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "y_proba = pipeline.predict_proba(X_test)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n",
    "    auc_score = roc_auc_score(y_test_bin[:, i], y_proba[:, i])\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {auc_score:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Chance')\n",
    "plt.title('ROC Curves (One-vs-Rest)', fontsize=16, weight='bold')\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "plt.legend(loc='lower right', fontsize=10, frameon=True)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8f03c-e632-44ce-a974-37ef2956e0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db94c37-a0f6-4770-bb81-c7154f76d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6864fe-ae3a-4b90-9ddc-2a6d86044eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64eb08-19ae-4bea-a4f0-27e598d23022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# STEP 8: SHAP FEATURE IMPORTANCE (Multiclass)\n",
    "# =============================================\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"shap\")\n",
    "\n",
    "# Create output folder for plots \n",
    "os.makedirs(\"shap_plots\", exist_ok=True)\n",
    "\n",
    "# Transform test data\n",
    "X_test_t = preprocessor.transform(X_test)\n",
    "\n",
    "# Get readable feature names \n",
    "raw_feature_names = preprocessor.get_feature_names_out()\n",
    "feature_names = [name.split(\"__\")[-1] for name in raw_feature_names]\n",
    "\n",
    "# Create SHAP Explainer\n",
    "explainer = shap.Explainer(classifier, X_test_t, feature_names=feature_names)\n",
    "shap_values = explainer(X_test_t)\n",
    "\n",
    "# Helper to group features \n",
    "def get_base_name(name):\n",
    "    return name.split(\"_\")[0] if \"_\" in name else name\n",
    "\n",
    "group_map = {name: get_base_name(name) for name in feature_names}\n",
    "\n",
    "def collapse_shap_values(shap_values, feature_names, group_map):\n",
    "    df = pd.DataFrame(np.abs(shap_values.values), columns=feature_names)\n",
    "    df_grouped = df.T.groupby(df.columns.map(group_map)).mean().T  # future-proof\n",
    "    return df_grouped\n",
    "\n",
    "# Style setup (publication-grade) \n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 300,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"font.size\": 12,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"axes.titlesize\": 13,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"figure.figsize\": (8, 5),\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": \"Arial\"\n",
    "})\n",
    "\n",
    "# Loop through each class \n",
    "class_names = np.unique(y_train)\n",
    "n_classes = shap_values.values.shape[2]\n",
    "\n",
    "print(f\" Detected multiclass target with {n_classes} classes.\")\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    df_grouped = collapse_shap_values(shap_values[:, :, i], feature_names, group_map)\n",
    "    mean_shap = df_grouped.mean().sort_values(ascending=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    mean_shap[:15].plot(kind=\"barh\", ax=ax, color=\"#4472C4\", edgecolor=\"black\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_title(f\"Mean |SHAP| Values ‚Äî Class {class_name}\", pad=12)\n",
    "    ax.set_xlabel(\"Mean Absolute SHAP Value\", labelpad=8)\n",
    "    ax.set_ylabel(\"Feature\", labelpad=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save image \n",
    "    save_path = f\"shap_plots/SHAP_importance_class_{class_name}.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    # Show image interactively \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e19019-c758-47cb-af90-285137aff820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87bdc7-c912-4f6a-bbd8-8fdc1c7c1bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd2fd7-44da-4c72-ada2-d9e79b3b8f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052a7db-a20f-4a3a-82a9-03e5ba75dbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c8e82-f4d4-4635-95aa-f7f88132d256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c3122-3526-44b5-b64a-c3bb7b9a0714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
