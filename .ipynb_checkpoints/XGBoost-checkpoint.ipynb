{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3e07c-04fd-4ee5-ba52-2a4da34637d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfe06d-7c3f-4722-9421-bc963c7aa725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c1ccd2-6bef-4752-903f-10d3e63037e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4656e2-e3ea-4450-ab74-1ec8a5a568b1",
   "metadata": {},
   "source": [
    "## 1. Import libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d306083-a1de-46ae-9691-14e06b3313fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, label_binarize\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa11a5ef-cc28-450f-85ec-d4c8a0657558",
   "metadata": {},
   "source": [
    "## 2. Read data and map the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd837dd-02cc-4fe6-9bab-2d318722ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "obesity = pd.read_csv(\"obesity.csv\")\n",
    "# change the target name from \"NObeyesdad\" to \"target\"\n",
    "obesity.rename(columns={\"NObeyesdad\": \"Target\"}, inplace=True)\n",
    "\n",
    "target_map = {\n",
    "    \"Insufficient_Weight\": 0,\n",
    "    \"Normal_Weight\": 1,\n",
    "    \"Overweight_Level_I\": 2,\n",
    "    \"Overweight_Level_II\": 3,\n",
    "    \"Obesity_Type_I\": 4,\n",
    "    \"Obesity_Type_II\": 5,\n",
    "    \"Obesity_Type_III\": 6\n",
    "}\n",
    "\n",
    "obesity[\"Target\"] = obesity[\"Target\"].map(target_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed102d79-19bc-4a1d-8007-04376aa6975c",
   "metadata": {},
   "source": [
    "## 3. Divide categorical and numerical features then split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560237a-706d-4a11-bb3a-e5d0292fdeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = obesity.drop(columns=[\"Target\"])\n",
    "y = obesity[\"Target\"]\n",
    "\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f958f1f-7b8a-4a1c-91c7-da89b988f438",
   "metadata": {},
   "source": [
    "## 4. Preprocessing by scaling the numerical features and one hot encoding for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a53d7-0c47-434e-be21-f78020ca5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_features),\n",
    "        ('cat', categorical_transformer, cat_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba16f2e-d54a-46f9-bcdd-a11bd95a8aa6",
   "metadata": {},
   "source": [
    "## 5. Create model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7fa287-dfae-4848-8b75-13d8ba6cf96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d9cec7-b46b-4834-8ded-d6c00efd1921",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed57174-4e88-478d-b4dd-5665da20b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 75, 100, 125],\n",
    "    'classifier__max_depth': [3, 4, 5],\n",
    "    'classifier__learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10],\n",
    "    'classifier__subsample': [0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1],\n",
    "    'classifier__colsample_bytree': [0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Running Grid Search for XGBoost hyperparameters...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n Selecte the best parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345e0068-357e-432a-93d0-74ec63aaa5da",
   "metadata": {},
   "source": [
    "## 7. Predict by using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded962d8-9c41-41bc-b02d-984468bb35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# Check train vs testing accuracy\n",
    "# Example using your pipeline (best_model)\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812f6bd-74a7-410a-b964-5933d411b483",
   "metadata": {},
   "source": [
    "## 8. Calculate the metrics: accuracy, recall, precision and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea5272-2a9b-4e88-9ca5-f4933c8fda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "rec = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"\\nðŸ“Š Performance Metrics:\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision (macro): {prec:.4f}\")\n",
    "print(f\"Recall (macro):    {rec:.4f}\")\n",
    "print(f\"F1-score (macro):  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb9549-df7b-41cc-9832-e03ff8f09a85",
   "metadata": {},
   "source": [
    "## 9. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bad2c2-7682-407c-9b37-71e60d306bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Confusion Matrix\", fontsize=14, weight='bold')\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c07e45-f7e7-4190-8c18-0e5b09667e12",
   "metadata": {},
   "source": [
    "## 10. ROC AUC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c05ce-e642-4580-8b18-39279e8799f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(y))\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "for i in range(n_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n",
    "    auc_score = roc_auc_score(y_test_bin[:, i], y_proba[:, i])\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {i} (AUC = {auc_score:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Chance')\n",
    "plt.title('ROC Curves (One-vs-Rest)', fontsize=16, weight='bold')\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "plt.legend(loc='lower right', fontsize=10, frameon=True)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = f\"ROC_AUC_XGBoost.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb1cf5-a313-4f8d-bef3-8c4f609a6c81",
   "metadata": {},
   "source": [
    "## 11. SHAP features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64eb08-19ae-4bea-a4f0-27e598d23022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"shap\")\n",
    "\n",
    "# Create output folder for plots \n",
    "os.makedirs(\"shap_plots\", exist_ok=True)\n",
    "\n",
    "# Transform test data\n",
    "X_test_t = preprocessor.transform(X_test)\n",
    "\n",
    "# Get readable feature names \n",
    "raw_feature_names = preprocessor.get_feature_names_out()\n",
    "feature_names = [name.split(\"__\")[-1] for name in raw_feature_names]\n",
    "\n",
    "# Create SHAP Explainer\n",
    "explainer = shap.Explainer(classifier, X_test_t, feature_names=feature_names)\n",
    "shap_values = explainer(X_test_t)\n",
    "\n",
    "# Helper to group features \n",
    "def get_base_name(name):\n",
    "    return name.split(\"_\")[0] if \"_\" in name else name\n",
    "\n",
    "group_map = {name: get_base_name(name) for name in feature_names}\n",
    "\n",
    "def collapse_shap_values(shap_values, feature_names, group_map):\n",
    "    df = pd.DataFrame(np.abs(shap_values.values), columns=feature_names)\n",
    "    df_grouped = df.T.groupby(df.columns.map(group_map)).mean().T  # future-proof\n",
    "    return df_grouped\n",
    "\n",
    "# Style setup (publication-grade) \n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 300,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"font.size\": 12,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"axes.titlesize\": 13,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"figure.figsize\": (8, 5),\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": \"Arial\"\n",
    "})\n",
    "\n",
    "# Loop through each class \n",
    "class_names = np.unique(y_train)\n",
    "n_classes = shap_values.values.shape[2]\n",
    "\n",
    "print(f\" Detected multiclass target with {n_classes} classes.\")\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    df_grouped = collapse_shap_values(shap_values[:, :, i], feature_names, group_map)\n",
    "    mean_shap = df_grouped.mean().sort_values(ascending=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    mean_shap[:15].plot(kind=\"barh\", ax=ax, color=\"#4472C4\", edgecolor=\"black\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_title(f\"Mean |SHAP| Values â€” Class {class_name}\", pad=12)\n",
    "    ax.set_xlabel(\"Mean Absolute SHAP Value\", labelpad=8)\n",
    "    ax.set_ylabel(\"Feature\", labelpad=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save image \n",
    "    save_path = f\"shap_plots/SHAP_importance_class_{class_name}.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    # Show image interactively \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e19019-c758-47cb-af90-285137aff820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87bdc7-c912-4f6a-bbd8-8fdc1c7c1bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd2fd7-44da-4c72-ada2-d9e79b3b8f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052a7db-a20f-4a3a-82a9-03e5ba75dbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c8e82-f4d4-4635-95aa-f7f88132d256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c3122-3526-44b5-b64a-c3bb7b9a0714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
